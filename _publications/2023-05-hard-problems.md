---
title: "Cheating to Identify Hard Problems for Neural Machine Translation"
collection: publications
permalink: /publications/hard-problems
authors:
  - Proyag Pal
  - Kenneth Heafield
date: 2023-05-07
venue: "<a href ='https://2023.eacl.org'>EACL</a> (Findings)"
paperurl: '/files/papers/hard-problems.pdf'
abstract: "We identify hard problems for neural machine translation models by analyzing progressively higher-scoring translations generated by letting models cheat to various degrees. If a system cheats and still gets something wrong, that suggests it is a hard problem. We experiment with two forms of cheating: providing the model a compressed representation of the target as an additional input, and fine-tuning on the test set. Contrary to popular belief, we find that the most frequent tokens are not necessarily the most accurately translated due to these often being function words and punctuation that can be used more flexibly in translation, or content words which can easily be paraphrased. We systematically analyze system outputs to identify categories of tokens which are particularly hard for the model to translate, and find that this includes certain types of named entities, subordinating conjunctions, and unknown and foreign words. We also encounter a phenomenon where words, often names, which were not infrequent in the training data are still repeatedly mistranslated by the models â€” we dub this the Fleetwood Mac problem."
---
